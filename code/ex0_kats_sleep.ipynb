{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b52d943-936a-4062-bf73-c3f24cb16331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install kats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b178b362-2b80-4209-bad8-5f10166aaea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext memory_profiler\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d70da5-a602-4e1a-b166-4b2e53f886df",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e433e5-27c3-4a2a-85f6-64e9f13e67bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage:  96.13 MB\n"
     ]
    }
   ],
   "source": [
    "from kats.tsfeatures.tsfeatures import TsFeatures\n",
    "from kats.consts import TimeSeriesData, TimeSeriesIterator\n",
    "from utils import get_data\n",
    "df_emg = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da0581d-3688-4c3b-80e4-73a8a0309f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01788797-c2b8-4c5d-85f5-d9b8bcc25385",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## testing time type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4810543e-ebb8-4d97-b540-7f6675b18986",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = TimeSeriesData(value=df_emg, time=pd.Series(np.arange(0, len(df_emg))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6358d1a3-c96e-469a-89ac-c6608a8ac128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1970-01-01 00:00:00.000000000\n",
       "1         1970-01-01 00:00:00.000000001\n",
       "2         1970-01-01 00:00:00.000000002\n",
       "3         1970-01-01 00:00:00.000000003\n",
       "4         1970-01-01 00:00:00.000000004\n",
       "                       ...             \n",
       "3599995   1970-01-01 00:00:00.003599995\n",
       "3599996   1970-01-01 00:00:00.003599996\n",
       "3599997   1970-01-01 00:00:00.003599997\n",
       "3599998   1970-01-01 00:00:00.003599998\n",
       "3599999   1970-01-01 00:00:00.003599999\n",
       "Length: 3600000, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data.time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421b058-4e54-4577-90ee-a05afa29e36d",
   "metadata": {},
   "source": [
    "## default example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e2559d-be08-465d-9e4c-d61207d96f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data_list = [TimeSeriesData(value=df_emg[c], time=df_emg.index) for c in df_emg.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cd6be51-8224-4af3-9317-5a63a1b00dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 1000\n",
    "fe = TsFeatures(\n",
    "    window_size=fs * 30,\n",
    "    window=30 * fs,\n",
    "    selected_features=['mean', 'var', 'length']\n",
    ")\n",
    "\n",
    "out = [fe.transform(ts) for ts in ts_data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4775c04-92e7-4fd8-893e-45d81275f9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>emg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-06-30 07:05:52.620232</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30 07:05:52.621232</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-30 07:05:52.622232</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-30 07:05:52.623232</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-30 07:05:52.624232</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599995</th>\n",
       "      <td>2021-06-30 08:05:52.615232</td>\n",
       "      <td>0.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599996</th>\n",
       "      <td>2021-06-30 08:05:52.616232</td>\n",
       "      <td>0.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599997</th>\n",
       "      <td>2021-06-30 08:05:52.617232</td>\n",
       "      <td>0.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599998</th>\n",
       "      <td>2021-06-30 08:05:52.618232</td>\n",
       "      <td>0.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599999</th>\n",
       "      <td>2021-06-30 08:05:52.619232</td>\n",
       "      <td>0.34375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3600000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              time      emg\n",
       "0       2021-06-30 07:05:52.620232  0.00000\n",
       "1       2021-06-30 07:05:52.621232  0.00000\n",
       "2       2021-06-30 07:05:52.622232  0.00000\n",
       "3       2021-06-30 07:05:52.623232  0.00000\n",
       "4       2021-06-30 07:05:52.624232  0.00000\n",
       "...                            ...      ...\n",
       "3599995 2021-06-30 08:05:52.615232  0.34375\n",
       "3599996 2021-06-30 08:05:52.616232  0.34375\n",
       "3599997 2021-06-30 08:05:52.617232  0.34375\n",
       "3599998 2021-06-30 08:05:52.618232  0.34375\n",
       "3599999 2021-06-30 08:05:52.619232  0.34375\n",
       "\n",
       "[3600000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ce85e6-9396-466b-9dcf-69e9d4f40082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'length': 3600000, 'mean': 0.6727282404899597, 'var': 0.07464560121297836},\n",
       " {'length': 3600000, 'mean': -0.09149625897407532, 'var': 0.20476381480693817},\n",
       " {'length': 3600000, 'mean': 0.2712729275226593, 'var': 0.17504480481147766},\n",
       " {'length': 3600000, 'mean': 0.6727282404899597, 'var': 0.07464560121297836},\n",
       " {'length': 3600000, 'mean': -0.09149625897407532, 'var': 0.20476381480693817}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23841219-d1c2-401f-8e23-93ad64d7f970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   length  5 non-null      int64  \n",
      " 1   mean    5 non-null      float64\n",
      " 2   var     5 non-null      float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 248.0 bytes\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(out).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28bbbd3c-8a4f-4456-9ca9-676209dcb1ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8e2e26635fc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     window=30 * fs,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mselected_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'var'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m ).transform(ts_data)\n\u001b[0m",
      "\u001b[0;32m~/jonas/projects/context_aware_health_monitoring/.caw_venv37/lib/python3.7/site-packages/kats/tsfeatures/tsfeatures.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mto_remove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mts_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_filter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0mto_remove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "# fs = 1000\n",
    "TsFeatures(\n",
    "#     window_size=fs * 30,\n",
    "#     window=30 * fs,\n",
    "    selected_features=['mean', 'var', 'length']\n",
    ").transform(ts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "111a9567-23f7-417d-a86b-323631c304eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4ff90a43c345>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/jonas/projects/context_aware_health_monitoring/.caw_venv37/lib/python3.7/site-packages/kats/tsfeatures/tsfeatures.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mto_remove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mts_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_filter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0mto_remove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "fe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23875fd-90da-4f57-9383-2c94c1f31fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "from tsflex.features import FeatureCollection, NumpyFuncWrapper\n",
    "from tsflex.features import FeatureDescriptor, MultipleFeatureDescriptors\n",
    "\n",
    "#----------------------------------------------------------------------------\n",
    "quantiles = [0.25, 0.5, 0.75]\n",
    "\n",
    "\n",
    "def type_wrapper(x: np.ndarray, type_wrapped_func, **kwargs):\n",
    "    return type_wrapped_func(x, **kwargs).astype(x.dtype)\n",
    "\n",
    "\n",
    "# -- 2. in-line functions\n",
    "#    You can define your functions locally; these will serialize flawleslly\n",
    "def slope(x):\n",
    "    return np.polyfit(np.arange(0, len(x)), x, 1)[0]\n",
    "\n",
    "\n",
    "f_slope = NumpyFuncWrapper(type_wrapper, output_names=\"slope\", type_wrapped_func=slope)\n",
    "\n",
    "# -- 3. Lambda's\n",
    "#    Or even use lambda's and other modules' functions\n",
    "def rms(x): return np.sqrt(np.mean(x**2))\n",
    "f_rms = NumpyFuncWrapper(rms, output_names=\"rms\")\n",
    "# f_rms = NumpyFuncWrapper(lambda x: np.sqrt(np.mean(x ** 2)), output_names=\"rms\")\n",
    "f_area = NumpyFuncWrapper(np.sum, output_names=\"area\")\n",
    "\n",
    "# (For convenience) we store the constructed `NumpyFuncWrappers` in a list\n",
    "segment_funcs = [\n",
    "    np.min,\n",
    "    np.max,\n",
    "    np.mean,\n",
    "    np.std,\n",
    "    np.var,\n",
    "    ss.skew,\n",
    "    ss.kurtosis,\n",
    "    f_slope,\n",
    "    f_rms,\n",
    "    f_area,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fd861d2-1dbb-491a-b5fc-2fa18b8f9610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage:  96.13 MB\n"
     ]
    }
   ],
   "source": [
    "from utils import get_data\n",
    "df_emg = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9dee99d-fb83-4969-842e-03c32b4ed659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "from joblib import wrap_non_picklable_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25ecef2a-7291-41e1-8d8b-552689b6e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fc = FeatureCollection(\n",
    "#     feature_descriptors=[\n",
    "#         MultipleFeatureDescriptors(\n",
    "#             functions=segment_funcs,\n",
    "#             series_names=[\"emg\", \"eog\", \"lso\", \"rio\", \"m1-a1\"],\n",
    "#             windows=[\"30s\"],\n",
    "#             strides=[\"10s\"],\n",
    "#         )\n",
    "#     ]\n",
    "# )\n",
    "# out = fc.calculate(data=df_emg, n_jobs=None, return_df=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38401c7b-04a5-4e84-ac74-88ec501d07ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FeatureCollection(\n",
    "    feature_descriptors=[\n",
    "        MultipleFeatureDescriptors(\n",
    "            functions=segment_funcs,\n",
    "            series_names=[\"emg\", \"eog\", \"lso\", \"rio\", \"m1-a1\"],\n",
    "            windows=[\"30s\"],\n",
    "            strides=[\"10s\"],\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee22478-6e8b-40cc-bf8b-febb3a675f45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: ../../tsflex/features/feature_collection.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurences   Line Contents\n",
       "============================================================\n",
       "   170    327.0 MiB    327.0 MiB           1       def calculate(\n",
       "   171                                                 self,\n",
       "   172                                                 data: Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]],\n",
       "   173                                                 return_df: Optional[bool] = False,\n",
       "   174                                                 window_idx: Optional[str] = 'end',\n",
       "   175                                                 approve_sparsity: Optional[bool] = False,\n",
       "   176                                                 show_progress: Optional[bool] = False,\n",
       "   177                                                 logging_file_path: Optional[Union[str, Path]] = None,\n",
       "   178                                                 n_jobs: Optional[int] = None,\n",
       "   179                                             ) -> Union[List[pd.DataFrame], pd.DataFrame]:\n",
       "   180                                                 \"\"\"Calculate features on the passed data.\n",
       "   181                                         \n",
       "   182                                                 Notes\n",
       "   183                                                 ------\n",
       "   184                                                 * The (column-)names of the series in `data` represent the names in the keys.\n",
       "   185                                                 * If a `logging_file_path` is provided, the execution (time) info can be\n",
       "   186                                                   retrieved by calling `logger.get_feature_logs(logging_file_path)`.\n",
       "   187                                                   Be aware that the `logging_file_path` gets cleared before the logger pushes\n",
       "   188                                                   logged messages. Hence, one should use a separate logging file for each\n",
       "   189                                                   constructed processing and feature instance with this library.\n",
       "   190                                         \n",
       "   191                                                 Parameters\n",
       "   192                                                 ----------\n",
       "   193                                                 data : Union[pd.Series, pd.DataFrame, List[Union[pd.Series, pd.DataFrame]]]\n",
       "   194                                                     Dataframe or Series or list thereof, with all the required data for the\n",
       "   195                                                     feature calculation. \\n\n",
       "   196                                                     **Remark**: each Series / DataFrame must have a `pd.DatetimeIndex`.\n",
       "   197                                                     **Remark**: we assume that each name / column is unique.\n",
       "   198                                                 return_df : bool, optional\n",
       "   199                                                     Whether the output needs to be a dataframe list or a DataFrame, by default \n",
       "   200                                                     False.\n",
       "   201                                                     If `True` the output dataframes will be merged to a DataFrame with an outer\n",
       "   202                                                     merge.\n",
       "   203                                                 window_idx : str, optional\n",
       "   204                                                     The window's index position which will be used as index for the\n",
       "   205                                                     feature_window aggregation. Must be either of: ['begin', 'middle', 'end'],\n",
       "   206                                                     by default 'end'. All features in this collection will use the same\n",
       "   207                                                     window_idx.\n",
       "   208                                                 approve_sparsity: bool, optional\n",
       "   209                                                     Bool indicating whether the user acknowledges that there may be sparsity \n",
       "   210                                                     (i.e., irregularly sampled data), by default False.\n",
       "   211                                                     If False and sparsity is observed, a warning is raised.\n",
       "   212                                                 show_progress: bool, optional\n",
       "   213                                                     If True, the progress will be shown with a progressbar, by default False.\n",
       "   214                                                 logging_file_path : Union[str, Path], optional\n",
       "   215                                                     The file path where the logged messages are stored. If `None`, then no\n",
       "   216                                                     logging `FileHandler` will be used and the logging messages are only pushed\n",
       "   217                                                     to stdout. Otherwise, a logging `FileHandler` will write the logged messages\n",
       "   218                                                     to the given file path.\n",
       "   219                                                 n_jobs : int, optional\n",
       "   220                                                     The number of processes used for the feature calculation. If `None`, then\n",
       "   221                                                     the number returned by `os.cpu_count()` is used, by default None. \\n\n",
       "   222                                                     If n_jobs is either 0 or 1, the code will be executed sequentially without\n",
       "   223                                                     creating a process pool. This is very useful when debugging, as the stack\n",
       "   224                                                     trace will be more comprehensible.\n",
       "   225                                         \n",
       "   226                                                     .. tip::\n",
       "   227                                                         * It takes on avg. _300ms_ to schedule everything with\n",
       "   228                                                           multiprocessing. So if your feature extraction code runs faster than\n",
       "   229                                                           ~1.5s, it might not be worth it to parallelize the process\n",
       "   230                                                           (and thus better set the `n_jobs` to 0-1).\n",
       "   231                                                         * This method its memory peaks are significantly lower when executed\n",
       "   232                                                           sequentially. Set the `n_jobs` to 0-1 if this matters.\n",
       "   233                                         \n",
       "   234                                                 Returns\n",
       "   235                                                 -------\n",
       "   236                                                 Union[List[pd.DataFrame], pd.DataFrame]\n",
       "   237                                                     The calculated features.\n",
       "   238                                         \n",
       "   239                                                 Raises\n",
       "   240                                                 ------\n",
       "   241                                                 KeyError\n",
       "   242                                                     Raised when a required key is not found in `data`.\n",
       "   243                                         \n",
       "   244                                                 \"\"\"\n",
       "   245                                                 # Delete other logging handlers\n",
       "   246    327.0 MiB      0.0 MiB           1           if len(logger.handlers) > 1:\n",
       "   247                                                     logger.handlers = [\n",
       "   248                                                         h for h in logger.handlers if type(h) == logging.StreamHandler\n",
       "   249                                                     ]\n",
       "   250    327.0 MiB      0.0 MiB           1           assert len(logger.handlers) == 1, \"Multiple logging StreamHandlers present!!\"\n",
       "   251                                         \n",
       "   252    327.0 MiB      0.0 MiB           1           if logging_file_path:\n",
       "   253                                                     if not isinstance(logging_file_path, Path):\n",
       "   254                                                         logging_file_path = Path(logging_file_path)\n",
       "   255                                                     if logging_file_path.exists():\n",
       "   256                                                         warnings.warn(\n",
       "   257                                                             f\"Logging file ({logging_file_path}) already exists. \"\n",
       "   258                                                             f\"This file will be overwritten!\"\n",
       "   259                                                         )\n",
       "   260                                                         # Clear the file\n",
       "   261                                                         #  -> because same FileHandler is used when calling this method twice\n",
       "   262                                                         open(logging_file_path, \"w\").close()\n",
       "   263                                                     f_handler = logging.FileHandler(logging_file_path, mode=\"w\")\n",
       "   264                                                     f_handler.setFormatter(\n",
       "   265                                                         logging.Formatter(\n",
       "   266                                                             \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
       "   267                                                         )\n",
       "   268                                                     )\n",
       "   269                                                     f_handler.setLevel(logging.INFO)\n",
       "   270                                                     logger.addHandler(f_handler)\n",
       "   271                                         \n",
       "   272                                                 # Convert the data to a series_dict\n",
       "   273    327.0 MiB      0.0 MiB           1           series_dict: Dict[str, pd.Series] = {}\n",
       "   274    327.1 MiB      0.0 MiB           6           for s in to_series_list(data):\n",
       "   275                                                     # Assert the assumptions we make!\n",
       "   276    327.1 MiB      0.0 MiB           5               assert isinstance(s.index, pd.DatetimeIndex)\n",
       "   277    327.1 MiB      0.1 MiB           5               assert s.index.is_monotonic_increasing\n",
       "   278                                         \n",
       "   279    327.1 MiB      0.0 MiB           5               if s.name in self.get_required_series():\n",
       "   280    327.1 MiB      0.0 MiB           5                   series_dict[str(s.name)] = s\n",
       "   281                                         \n",
       "   282    327.1 MiB      0.0 MiB           1           calculated_feature_list: List[pd.DataFrame] = []\n",
       "   283                                         \n",
       "   284    327.1 MiB      0.0 MiB           1           if n_jobs in [0, 1]:\n",
       "   285                                                     # print('Executing feature extraction sequentially')\n",
       "   286                                                     for stroll, func in self._stroll_feature_generator(\n",
       "   287                                                         series_dict, window_idx, approve_sparsity\n",
       "   288                                                     ):\n",
       "   289                                                         calculated_feature_list.append(stroll.apply_func(func))\n",
       "   290                                                 else:\n",
       "   291                                                     stroll_feats = [\n",
       "   292    327.5 MiB      0.4 MiB          53                   x for x in self._stroll_feature_generator(\n",
       "   293    327.5 MiB      0.0 MiB           1                       series_dict, window_idx, approve_sparsity\n",
       "   294                                                         )\n",
       "   295                                                     ]\n",
       "   296    327.7 MiB      0.2 MiB           1               pool = mp.Pool(n_jobs)\n",
       "   297    368.8 MiB     41.2 MiB           1               results = pool.imap(self._executor, stroll_feats)\n",
       "   298    369.2 MiB      0.3 MiB          51               for f in results:\n",
       "   299    369.2 MiB      0.0 MiB          50                   calculated_feature_list.append(f)\n",
       "   300    369.2 MiB      0.0 MiB           1               pool.close()\n",
       "   301    369.7 MiB      0.6 MiB           1               pool.join()\n",
       "   302                                         \n",
       "   303                                                     # https://pathos.readthedocs.io/en/latest/pathos.html#usage\n",
       "   304                                                     # with ProcessPool(nodes=n_jobs, source=True) as pool:\n",
       "   305                                                     #     results = pool.uimap(\n",
       "   306                                                     #         self._executor,\n",
       "   307                                                     #         self._stroll_feature_generator(\n",
       "   308                                                     #             series_dict, window_idx, approve_sparsity\n",
       "   309                                                     #         )\n",
       "   310                                                     #     )\n",
       "   311                                                     #     if show_progress:\n",
       "   312                                                     #         results = tqdm(results, total=len(self._feature_desc_dict))\n",
       "   313                                                     #     for f in results:\n",
       "   314                                                     #         calculated_feature_list.append(f)\n",
       "   315                                                     #     # Close & join - see: https://github.com/uqfoundation/pathos/issues/131\n",
       "   316                                                     #     pool.close()\n",
       "   317                                                     #     pool.join()\n",
       "   318                                                     #     # Clear because: https://github.com/uqfoundation/pathos/issues/111\n",
       "   319                                                     #     pool.clear()\n",
       "   320                                         \n",
       "   321    369.7 MiB      0.0 MiB           1           if return_df:\n",
       "   322    369.7 MiB      0.0 MiB           1               df_merged = pd.DataFrame()\n",
       "   323    370.3 MiB      0.0 MiB          51               for calculated_feature in calculated_feature_list:\n",
       "   324    370.3 MiB      0.0 MiB          50                   df_merged = pd.merge(\n",
       "   325    370.3 MiB      0.0 MiB          50                       left=df_merged,\n",
       "   326    370.3 MiB      0.0 MiB          50                       right=calculated_feature,\n",
       "   327    370.3 MiB      0.0 MiB          50                       how=\"outer\",\n",
       "   328    370.3 MiB      0.0 MiB          50                       left_index=True,\n",
       "   329    370.3 MiB      0.6 MiB          50                       right_index=True,\n",
       "   330                                                         )\n",
       "   331    370.3 MiB      0.0 MiB           1               return df_merged\n",
       "   332                                                 else:\n",
       "   333                                                     return calculated_feature_list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mprun -f fc.calculate fc.calculate(data=df_emg, n_jobs=10, return_df=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7765ea7b-c435-4439-a3d7-71e6fd490a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
